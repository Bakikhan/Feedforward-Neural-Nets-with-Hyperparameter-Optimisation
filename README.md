# Feedforward-Neural-Nets-with-Hyperparameter-Optimisation
Machine learning algorithms are known to solve a problem using optimizations methods , The optimization method involves many hyper parameters and layers that decide the efficiency of its problem solving, hyperparameters and layers are responsible for fitting the model to the data . There are two kinds of hyperparameter optimization i.e. manual search and automatic methods . Manual optimization works by assigning hyperparameters and other aspects manually , there is no rule or sequence it solely depends on trial and error and intuition also the tuning of those hyperparameters is not reproducible , to counter this situation automatic hyperparameter optimization algorithms are used such as grid search and random search optimization algorithms , both of them achieves automatic tuning and can obtain optimal value but have some constraints to them, grid search efficiency decreases as more hyperparameters are tuned and range increases where as in random optimization is not reliable for training some complex models. Hyper parameter optimization achieved from Bayesian optimization algorithm outperforms any other optimization models since it is an effective method that can solve costly functions or time consuming . In this report the objective is to use the Bayesian model to fine tune the hyperparameters of a feedforward neural network using Bayesian process.
